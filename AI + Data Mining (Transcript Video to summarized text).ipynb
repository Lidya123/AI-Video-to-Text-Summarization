{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 as bs #beautiful Soup --> pulls data from html/xml files\n",
    "import urllib.request\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ibm_watson in c:\\users\\asus\\anaconda3\\lib\\site-packages (5.3.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from ibm_watson) (2.24.0)\n",
      "Requirement already satisfied: ibm-cloud-sdk-core==3.*,>=3.3.6 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from ibm_watson) (3.12.0)\n",
      "Requirement already satisfied: websocket-client==1.1.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from ibm_watson) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from ibm_watson) (2.8.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.0->ibm_watson) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.0->ibm_watson) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.0->ibm_watson) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.0->ibm_watson) (3.0.4)\n",
      "Requirement already satisfied: PyJWT<3.0.0,>=2.0.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from ibm-cloud-sdk-core==3.*,>=3.3.6->ibm_watson) (2.3.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from python-dateutil>=2.5.3->ibm_watson) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "#installing libraries\n",
    "!pip install ibm_watson \n",
    "#AI --> Q&A,PREDICTIONS,AUTOMATE COMPLEX PROCESSES\n",
    "#!pip install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing dependencies\n",
    "import subprocess \n",
    "from ibm_watson import SpeechToTextV1\n",
    "from ibm_watson.websocket import RecognizeCallback, AudioSource\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator \n",
    "#authenticate speech to text service "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command ='ffmpeg -i aiml.mkv -ab 160k -ar 44100 -vn aiml.wav'   #FFmpeg --> transcoding, streaming etc .. (.mkv, .flv, and .mov.)\n",
    "subprocess.call(command, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup STT services\n",
    "apikey = 'pFtpG-uagKwRJLhP4TosJMw14-LIWq9Ok9fzPQZKAEE9'\n",
    "url = 'https://api.au-syd.speech-to-text.watson.cloud.ibm.com/instances/e1018c30-9f10-47d9-8f40-f048c60d0376'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup service\n",
    "authenticator = IAMAuthenticator(apikey)\n",
    "stt = SpeechToTextV1(authenticator=authenticator)\n",
    "stt.set_service_url(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open audio source and convert \n",
    "with open('aiml.wav', 'rb') as f:\n",
    "    res = stt.recognize(audio=f, content_type='audio/wav', model='en-AU_NarrowbandModel').get_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result_index': 0,\n",
       " 'results': [{'final': True,\n",
       "   'alternatives': [{'transcript': 'ever wondered about the differences between ',\n",
       "     'confidence': 0.93}]},\n",
       "  {'final': True,\n",
       "   'alternatives': [{'transcript': \"M. L. deal and DS well we're about to explore all of those today stated so let's dive right into it so AI versus ML this is deal with the DS a whole bunch of judging but within a clarify all of that right up so it took things often take a look at A. R. \",\n",
       "     'confidence': 0.74}]},\n",
       "  {'final': True,\n",
       "   'alternatives': [{'transcript': 'so A. I. is really to do with the ability of computers and machines to perform tasks without explicitly programming them otherwise known as the ability for computers and machine to think by themselves so we typically break out into two categories these are generally I know a ',\n",
       "     'confidence': 0.94}]},\n",
       "  {'final': True,\n",
       "   'alternatives': [{'transcript': 'generally I typically refers to the ability for a computer a machine to be able to handle a wide variety of type I think humans have the ability to do a whole heap of stuff we can see we can speak we can here we can read we can drive we can do a whole range of things the ability for AI and machine to be able to do a broad range of tasks similar to human is what we typically referred to as general ',\n",
       "     'confidence': 0.88}]},\n",
       "  {'final': True,\n",
       "   'alternatives': [{'transcript': \"now with still a little bit of a while away from true general A. either that's not to say it's not to come now that narrow A. I. on the other hand is the ability for a machine to handle a really simple or really narrow range of time so that could possibly be the ability to translate speech to text or to classify images as having different categories or the ability to predict how prices for example all of these are examples of narrow A. I. so I'm going to be painting a bunch of visual imagery to help you remember some of these topics so the first one in terms of breaking out general and narrow AI or the ability to remember general an hour is just picture a really narrow really skinny general in your mind so that way you know that there's two different types of A. R. general America now onto the next up machine learning so take a look at being broken up into general and narrow but how does machine learning fit into this well machine learning is the application of narrow a item specific type now when we typically talk about machine learning we often compared to traditional programme so in traditional programming with applied data plus rules or conditional logic and get answers now in machine learning on the other hand we provide data plus historical answers to get rules we can then pass new data to get new answers so this is a bit of a change in the paradigm of how computer scientists and machine learning engineers are building programmes these days so what are some typical machine learning type well we probably break out machine learning into three categories either supervised learning unsupervised learning and semi supervised learning so let's take a look at supervised learning first so supervisor can be broadly broken out into two categories either classification and regression classification is also do with gripping things into categories all labels so they had a big data set on all the different types of pizzas you'd like and whether or not you'd like them yes or no you could take that data and pass it through to a classification algorithm to help it learn which types of pizzas you like so then when you pass through a new list of ingredients it \",\n",
       "     'confidence': 0.86}]},\n",
       "  {'final': True,\n",
       "   'alternatives': [{'transcript': \"it would be able to predict yes you would like that pizza or note you might not regression on the other hand is all to do with predicting continuous variable some great examples of regression our sales forecasting and predicting prices of houses so that encapsulate supervised learning now what about unsupervised learning well there's two key things to think about when you think of unsupervised learning visa really clustering so the ability to group people together so I'm so you wanted to group together high performing and low performing and media performing employee or high value low value medium value customers or a whole bunch of other different types of data but really it's all to do with grouping things together now dimensionality reduction on the other hand is all to do with chain dancing the features that you've got within a machine learning model so a lot of the time you might start out with a huge data set with a lot of column and you're not really sure which of those columns are important for you machine learning model dimensionality reduction helps you reduce the number of columns that you've got so that you can really focus on the important one now in order to remember supervised learning and unsupervised learning I'd suggest you remember this initial isn't Christopher robin courted up so that way you remember classification regression clustering and dimensionality reduction so that takes care of supervised and unsupervised learning board about semi supervised learning well this is where reinforcement learning comes in now reinforcement learning has four key things these are an agent an action environment and the reward it's similar to how you might choose to condition a dog a dog might do something right and you might reward it with a piece of food in a similar way we train reinforcement learning models to act in a correct way in a given environment in order to learn appropriate actions given that specific environment now the best way to remember reinforcement learning techniques is remember area fifty one so that way you remember agent reward environment and actions okay so that takes care of machine learning now to tell a little bit deeper and get into deep plan so \",\n",
       "     'confidence': 0.9}]},\n",
       "  {'final': True,\n",
       "   'alternatives': [{'transcript': \"%HESITATION deep learning is a subset of machine learning and really it's to do with performing machine learning tasks using deep neural networks now did your networks and networks that have multiple hidden late so if you've ever seen a diagram that looks sort of like this this is a representation of a neural network but specifically in this case this is a deep neural network because it had multiple hidden layers now the best way to remember deep learning is to remember that deep learning is just like an onion has multiple a little bit like Shrek now that's what it covers AI ML and deal what about data phone well they decide is the practise that sit over \",\n",
       "     'confidence': 0.83}]},\n",
       "  {'final': True,\n",
       "   'alternatives': [{'transcript': \"L. India it basically is the art of extracting knowledge insight and meaning from data the best way to remember the key components of data science I don't look at the cristiana framework so the Crispian framework stands for the cross industry standard process for data mining and basically it's a framework to help you along your way to producing really good data science project now there's sixty steps in the date and time to process visa business understanding so understanding the business that you're working with and the environment in which they operate to data understanding so understanding the data that you've got on hand so whether or not you've got missing values visualising that data and taking a look at some summary statistics with then got date of preparation so this is all to do with getting our data ready for modelling in this step we might perform some feature engineering increasing your columns we might feel into missing values and a whole bunch of other data preparation steps like for example splitting a data into training and testing next we've got my favourite which is model this is all to do with training your machine learning algorithms to perform well on a specific type once we trained our models in that modelling step we get on to the evaluation given that we've trained our model we want to make sure that it's going to work well once we deployed into the real world this is what the evaluation step is all about in this step we try to check whether or not a model is likely to perform while using specific evaluation metrics now once we've gone through all of that the last step is to go and deployed a model in order to deploy a model we could release it as a rest API containerized it up or save it as a wondering so we can go and use it elsewhere now a great way to remember Christie and this rumour Barry drove directly to the medical emergency department that way you remember business understanding data understanding data preparation modelling evaluation and deployment now I've talked a lot about period but whether the pipe and packages that you typically see used fit into this framework well in terms of data sites number part painted in matte properly \",\n",
       "     'confidence': 0.86}]},\n",
       "  {'final': True,\n",
       "   'alternatives': [{'transcript': \"probably going to be the most important packages that you see floating around number and panders help you traverse and explore your data and really work with your data in terms of performing manipulation and data preparation maps what leave in seaborne help you visualise that data and explore it even further now the most important likely in terms of machine learning is probably psychic learnt so so I could learn been around for quite some time and gives you a whole bunch of really powerful algorithms in utilities to help use them to train your machine learning models now declining is becoming increasingly popular and there's a large number of libraries that can help you perform deep learning some of which which are notable attempts of load carriers pi torch and piano just a name a few and that about wraps up versus an old versus deal versus dear thanks so much for choosing in guys hopefully you found this video useful if you did be sure to give it a thumbs up and hit them strive until next time T. \",\n",
       "     'confidence': 0.83}]}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['result_index', 'results'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res['results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [result['alternatives'][0]['transcript'].rstrip() + '.\\n' for result in res['results']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [para[0].title() + para[1:] for para in text]\n",
    "transcript = ''.join(text)\n",
    "with open('aiml_converted.txt', 'w') as out:\n",
    "    out.writelines(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ever wondered about the differences between.\\n',\n",
       " \"M. L. deal and DS well we're about to explore all of those today stated so let's dive right into it so AI versus ML this is deal with the DS a whole bunch of judging but within a clarify all of that right up so it took things often take a look at A. R..\\n\",\n",
       " 'So A. I. is really to do with the ability of computers and machines to perform tasks without explicitly programming them otherwise known as the ability for computers and machine to think by themselves so we typically break out into two categories these are generally I know a.\\n',\n",
       " 'Generally I typically refers to the ability for a computer a machine to be able to handle a wide variety of type I think humans have the ability to do a whole heap of stuff we can see we can speak we can here we can read we can drive we can do a whole range of things the ability for AI and machine to be able to do a broad range of tasks similar to human is what we typically referred to as general.\\n',\n",
       " \"Now with still a little bit of a while away from true general A. either that's not to say it's not to come now that narrow A. I. on the other hand is the ability for a machine to handle a really simple or really narrow range of time so that could possibly be the ability to translate speech to text or to classify images as having different categories or the ability to predict how prices for example all of these are examples of narrow A. I. so I'm going to be painting a bunch of visual imagery to help you remember some of these topics so the first one in terms of breaking out general and narrow AI or the ability to remember general an hour is just picture a really narrow really skinny general in your mind so that way you know that there's two different types of A. R. general America now onto the next up machine learning so take a look at being broken up into general and narrow but how does machine learning fit into this well machine learning is the application of narrow a item specific type now when we typically talk about machine learning we often compared to traditional programme so in traditional programming with applied data plus rules or conditional logic and get answers now in machine learning on the other hand we provide data plus historical answers to get rules we can then pass new data to get new answers so this is a bit of a change in the paradigm of how computer scientists and machine learning engineers are building programmes these days so what are some typical machine learning type well we probably break out machine learning into three categories either supervised learning unsupervised learning and semi supervised learning so let's take a look at supervised learning first so supervisor can be broadly broken out into two categories either classification and regression classification is also do with gripping things into categories all labels so they had a big data set on all the different types of pizzas you'd like and whether or not you'd like them yes or no you could take that data and pass it through to a classification algorithm to help it learn which types of pizzas you like so then when you pass through a new list of ingredients it.\\n\",\n",
       " \"It would be able to predict yes you would like that pizza or note you might not regression on the other hand is all to do with predicting continuous variable some great examples of regression our sales forecasting and predicting prices of houses so that encapsulate supervised learning now what about unsupervised learning well there's two key things to think about when you think of unsupervised learning visa really clustering so the ability to group people together so I'm so you wanted to group together high performing and low performing and media performing employee or high value low value medium value customers or a whole bunch of other different types of data but really it's all to do with grouping things together now dimensionality reduction on the other hand is all to do with chain dancing the features that you've got within a machine learning model so a lot of the time you might start out with a huge data set with a lot of column and you're not really sure which of those columns are important for you machine learning model dimensionality reduction helps you reduce the number of columns that you've got so that you can really focus on the important one now in order to remember supervised learning and unsupervised learning I'd suggest you remember this initial isn't Christopher robin courted up so that way you remember classification regression clustering and dimensionality reduction so that takes care of supervised and unsupervised learning board about semi supervised learning well this is where reinforcement learning comes in now reinforcement learning has four key things these are an agent an action environment and the reward it's similar to how you might choose to condition a dog a dog might do something right and you might reward it with a piece of food in a similar way we train reinforcement learning models to act in a correct way in a given environment in order to learn appropriate actions given that specific environment now the best way to remember reinforcement learning techniques is remember area fifty one so that way you remember agent reward environment and actions okay so that takes care of machine learning now to tell a little bit deeper and get into deep plan so.\\n\",\n",
       " \"%HESITATION deep learning is a subset of machine learning and really it's to do with performing machine learning tasks using deep neural networks now did your networks and networks that have multiple hidden late so if you've ever seen a diagram that looks sort of like this this is a representation of a neural network but specifically in this case this is a deep neural network because it had multiple hidden layers now the best way to remember deep learning is to remember that deep learning is just like an onion has multiple a little bit like Shrek now that's what it covers AI ML and deal what about data phone well they decide is the practise that sit over.\\n\",\n",
       " \"L. India it basically is the art of extracting knowledge insight and meaning from data the best way to remember the key components of data science I don't look at the cristiana framework so the Crispian framework stands for the cross industry standard process for data mining and basically it's a framework to help you along your way to producing really good data science project now there's sixty steps in the date and time to process visa business understanding so understanding the business that you're working with and the environment in which they operate to data understanding so understanding the data that you've got on hand so whether or not you've got missing values visualising that data and taking a look at some summary statistics with then got date of preparation so this is all to do with getting our data ready for modelling in this step we might perform some feature engineering increasing your columns we might feel into missing values and a whole bunch of other data preparation steps like for example splitting a data into training and testing next we've got my favourite which is model this is all to do with training your machine learning algorithms to perform well on a specific type once we trained our models in that modelling step we get on to the evaluation given that we've trained our model we want to make sure that it's going to work well once we deployed into the real world this is what the evaluation step is all about in this step we try to check whether or not a model is likely to perform while using specific evaluation metrics now once we've gone through all of that the last step is to go and deployed a model in order to deploy a model we could release it as a rest API containerized it up or save it as a wondering so we can go and use it elsewhere now a great way to remember Christie and this rumour Barry drove directly to the medical emergency department that way you remember business understanding data understanding data preparation modelling evaluation and deployment now I've talked a lot about period but whether the pipe and packages that you typically see used fit into this framework well in terms of data sites number part painted in matte properly.\\n\",\n",
       " \"Probably going to be the most important packages that you see floating around number and panders help you traverse and explore your data and really work with your data in terms of performing manipulation and data preparation maps what leave in seaborne help you visualise that data and explore it even further now the most important likely in terms of machine learning is probably psychic learnt so so I could learn been around for quite some time and gives you a whole bunch of really powerful algorithms in utilities to help use them to train your machine learning models now declining is becoming increasingly popular and there's a large number of libraries that can help you perform deep learning some of which which are notable attempts of load carriers pi torch and piano just a name a few and that about wraps up versus an old versus deal versus dear thanks so much for choosing in guys hopefully you found this video useful if you did be sure to give it a thumbs up and hit them strive until next time T..\\n\"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ever wondered about the differences between.\\nM. L. deal and DS well we're about to explore all of those today stated so let's dive right into it so AI versus ML this is deal with the DS a whole bunch of judging but within a clarify all of that right up so it took things often take a look at A. R..\\nSo A. I. is really to do with the ability of computers and machines to perform tasks without explicitly programming them otherwise known as the ability for computers and machine to think by themselves so we typically break out into two categories these are generally I know a.\\nGenerally I typically refers to the ability for a computer a machine to be able to handle a wide variety of type I think humans have the ability to do a whole heap of stuff we can see we can speak we can here we can read we can drive we can do a whole range of things the ability for AI and machine to be able to do a broad range of tasks similar to human is what we typically referred to as general.\\nNow with still a little bit of a while away from true general A. either that's not to say it's not to come now that narrow A. I. on the other hand is the ability for a machine to handle a really simple or really narrow range of time so that could possibly be the ability to translate speech to text or to classify images as having different categories or the ability to predict how prices for example all of these are examples of narrow A. I. so I'm going to be painting a bunch of visual imagery to help you remember some of these topics so the first one in terms of breaking out general and narrow AI or the ability to remember general an hour is just picture a really narrow really skinny general in your mind so that way you know that there's two different types of A. R. general America now onto the next up machine learning so take a look at being broken up into general and narrow but how does machine learning fit into this well machine learning is the application of narrow a item specific type now when we typically talk about machine learning we often compared to traditional programme so in traditional programming with applied data plus rules or conditional logic and get answers now in machine learning on the other hand we provide data plus historical answers to get rules we can then pass new data to get new answers so this is a bit of a change in the paradigm of how computer scientists and machine learning engineers are building programmes these days so what are some typical machine learning type well we probably break out machine learning into three categories either supervised learning unsupervised learning and semi supervised learning so let's take a look at supervised learning first so supervisor can be broadly broken out into two categories either classification and regression classification is also do with gripping things into categories all labels so they had a big data set on all the different types of pizzas you'd like and whether or not you'd like them yes or no you could take that data and pass it through to a classification algorithm to help it learn which types of pizzas you like so then when you pass through a new list of ingredients it.\\nIt would be able to predict yes you would like that pizza or note you might not regression on the other hand is all to do with predicting continuous variable some great examples of regression our sales forecasting and predicting prices of houses so that encapsulate supervised learning now what about unsupervised learning well there's two key things to think about when you think of unsupervised learning visa really clustering so the ability to group people together so I'm so you wanted to group together high performing and low performing and media performing employee or high value low value medium value customers or a whole bunch of other different types of data but really it's all to do with grouping things together now dimensionality reduction on the other hand is all to do with chain dancing the features that you've got within a machine learning model so a lot of the time you might start out with a huge data set with a lot of column and you're not really sure which of those columns are important for you machine learning model dimensionality reduction helps you reduce the number of columns that you've got so that you can really focus on the important one now in order to remember supervised learning and unsupervised learning I'd suggest you remember this initial isn't Christopher robin courted up so that way you remember classification regression clustering and dimensionality reduction so that takes care of supervised and unsupervised learning board about semi supervised learning well this is where reinforcement learning comes in now reinforcement learning has four key things these are an agent an action environment and the reward it's similar to how you might choose to condition a dog a dog might do something right and you might reward it with a piece of food in a similar way we train reinforcement learning models to act in a correct way in a given environment in order to learn appropriate actions given that specific environment now the best way to remember reinforcement learning techniques is remember area fifty one so that way you remember agent reward environment and actions okay so that takes care of machine learning now to tell a little bit deeper and get into deep plan so.\\n%HESITATION deep learning is a subset of machine learning and really it's to do with performing machine learning tasks using deep neural networks now did your networks and networks that have multiple hidden late so if you've ever seen a diagram that looks sort of like this this is a representation of a neural network but specifically in this case this is a deep neural network because it had multiple hidden layers now the best way to remember deep learning is to remember that deep learning is just like an onion has multiple a little bit like Shrek now that's what it covers AI ML and deal what about data phone well they decide is the practise that sit over.\\nL. India it basically is the art of extracting knowledge insight and meaning from data the best way to remember the key components of data science I don't look at the cristiana framework so the Crispian framework stands for the cross industry standard process for data mining and basically it's a framework to help you along your way to producing really good data science project now there's sixty steps in the date and time to process visa business understanding so understanding the business that you're working with and the environment in which they operate to data understanding so understanding the data that you've got on hand so whether or not you've got missing values visualising that data and taking a look at some summary statistics with then got date of preparation so this is all to do with getting our data ready for modelling in this step we might perform some feature engineering increasing your columns we might feel into missing values and a whole bunch of other data preparation steps like for example splitting a data into training and testing next we've got my favourite which is model this is all to do with training your machine learning algorithms to perform well on a specific type once we trained our models in that modelling step we get on to the evaluation given that we've trained our model we want to make sure that it's going to work well once we deployed into the real world this is what the evaluation step is all about in this step we try to check whether or not a model is likely to perform while using specific evaluation metrics now once we've gone through all of that the last step is to go and deployed a model in order to deploy a model we could release it as a rest API containerized it up or save it as a wondering so we can go and use it elsewhere now a great way to remember Christie and this rumour Barry drove directly to the medical emergency department that way you remember business understanding data understanding data preparation modelling evaluation and deployment now I've talked a lot about period but whether the pipe and packages that you typically see used fit into this framework well in terms of data sites number part painted in matte properly.\\nProbably going to be the most important packages that you see floating around number and panders help you traverse and explore your data and really work with your data in terms of performing manipulation and data preparation maps what leave in seaborne help you visualise that data and explore it even further now the most important likely in terms of machine learning is probably psychic learnt so so I could learn been around for quite some time and gives you a whole bunch of really powerful algorithms in utilities to help use them to train your machine learning models now declining is becoming increasingly popular and there's a large number of libraries that can help you perform deep learning some of which which are notable attempts of load carriers pi torch and piano just a name a few and that about wraps up versus an old versus deal versus dear thanks so much for choosing in guys hopefully you found this video useful if you did be sure to give it a thumbs up and hit them strive until next time T..\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [para[0].title() + para[1:] for para in text]\n",
    "transcript = ''.join(text)\n",
    "with open('aiml_converted.txt','w') as out:\n",
    "    out.writelines(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk #language processing\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "word_frequencies = {}\n",
    "for word in nltk.word_tokenize(transcript):\n",
    "    if word not in stopwords:\n",
    "        if word not in word_frequencies.keys():\n",
    "            word_frequencies[word] = 1\n",
    "        else:\n",
    "            word_frequencies[word] += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ever': 1,\n",
       " 'wondered': 1,\n",
       " 'differences': 1,\n",
       " '.': 7,\n",
       " 'M.': 1,\n",
       " 'L.': 2,\n",
       " 'deal': 4,\n",
       " 'DS': 2,\n",
       " 'well': 9,\n",
       " \"'re\": 3,\n",
       " 'explore': 3,\n",
       " 'today': 1,\n",
       " 'stated': 1,\n",
       " 'let': 2,\n",
       " \"'s\": 14,\n",
       " 'dive': 1,\n",
       " 'right': 3,\n",
       " 'AI': 4,\n",
       " 'versus': 4,\n",
       " 'ML': 2,\n",
       " 'whole': 6,\n",
       " 'bunch': 5,\n",
       " 'judging': 1,\n",
       " 'within': 2,\n",
       " 'clarify': 1,\n",
       " 'took': 1,\n",
       " 'things': 6,\n",
       " 'often': 2,\n",
       " 'take': 4,\n",
       " 'look': 5,\n",
       " 'A.': 6,\n",
       " 'R': 1,\n",
       " '..': 2,\n",
       " 'So': 1,\n",
       " 'I.': 3,\n",
       " 'really': 13,\n",
       " 'ability': 10,\n",
       " 'computers': 2,\n",
       " 'machines': 1,\n",
       " 'perform': 5,\n",
       " 'tasks': 3,\n",
       " 'without': 1,\n",
       " 'explicitly': 1,\n",
       " 'programming': 2,\n",
       " 'otherwise': 1,\n",
       " 'known': 1,\n",
       " 'machine': 20,\n",
       " 'think': 4,\n",
       " 'typically': 5,\n",
       " 'break': 2,\n",
       " 'two': 4,\n",
       " 'categories': 5,\n",
       " 'generally': 1,\n",
       " 'I': 9,\n",
       " 'know': 2,\n",
       " 'Generally': 1,\n",
       " 'refers': 1,\n",
       " 'computer': 2,\n",
       " 'able': 3,\n",
       " 'handle': 2,\n",
       " 'wide': 1,\n",
       " 'variety': 1,\n",
       " 'type': 4,\n",
       " 'humans': 1,\n",
       " 'heap': 1,\n",
       " 'stuff': 1,\n",
       " 'see': 3,\n",
       " 'speak': 1,\n",
       " 'read': 1,\n",
       " 'drive': 1,\n",
       " 'range': 3,\n",
       " 'broad': 1,\n",
       " 'similar': 3,\n",
       " 'human': 1,\n",
       " 'referred': 1,\n",
       " 'general': 7,\n",
       " 'Now': 1,\n",
       " 'still': 1,\n",
       " 'little': 3,\n",
       " 'bit': 4,\n",
       " 'away': 1,\n",
       " 'true': 1,\n",
       " 'either': 3,\n",
       " 'say': 1,\n",
       " 'come': 1,\n",
       " 'narrow': 7,\n",
       " 'hand': 5,\n",
       " 'simple': 1,\n",
       " 'time': 5,\n",
       " 'could': 4,\n",
       " 'possibly': 1,\n",
       " 'translate': 1,\n",
       " 'speech': 1,\n",
       " 'text': 1,\n",
       " 'classify': 1,\n",
       " 'images': 1,\n",
       " 'different': 4,\n",
       " 'predict': 2,\n",
       " 'prices': 2,\n",
       " 'example': 2,\n",
       " 'examples': 2,\n",
       " \"'m\": 2,\n",
       " 'going': 3,\n",
       " 'painting': 1,\n",
       " 'visual': 1,\n",
       " 'imagery': 1,\n",
       " 'help': 7,\n",
       " 'remember': 13,\n",
       " 'topics': 1,\n",
       " 'first': 2,\n",
       " 'one': 3,\n",
       " 'terms': 4,\n",
       " 'breaking': 1,\n",
       " 'hour': 1,\n",
       " 'picture': 1,\n",
       " 'skinny': 1,\n",
       " 'mind': 1,\n",
       " 'way': 11,\n",
       " 'types': 4,\n",
       " 'R.': 1,\n",
       " 'America': 1,\n",
       " 'onto': 1,\n",
       " 'next': 3,\n",
       " 'learning': 35,\n",
       " 'broken': 2,\n",
       " 'fit': 2,\n",
       " 'application': 1,\n",
       " 'item': 1,\n",
       " 'specific': 4,\n",
       " 'talk': 1,\n",
       " 'compared': 1,\n",
       " 'traditional': 2,\n",
       " 'programme': 1,\n",
       " 'applied': 1,\n",
       " 'data': 25,\n",
       " 'plus': 2,\n",
       " 'rules': 2,\n",
       " 'conditional': 1,\n",
       " 'logic': 1,\n",
       " 'get': 5,\n",
       " 'answers': 3,\n",
       " 'provide': 1,\n",
       " 'historical': 1,\n",
       " 'pass': 3,\n",
       " 'new': 3,\n",
       " 'change': 1,\n",
       " 'paradigm': 1,\n",
       " 'scientists': 1,\n",
       " 'engineers': 1,\n",
       " 'building': 1,\n",
       " 'programmes': 1,\n",
       " 'days': 1,\n",
       " 'typical': 1,\n",
       " 'probably': 2,\n",
       " 'three': 1,\n",
       " 'supervised': 7,\n",
       " 'unsupervised': 5,\n",
       " 'semi': 2,\n",
       " 'supervisor': 1,\n",
       " 'broadly': 1,\n",
       " 'classification': 4,\n",
       " 'regression': 4,\n",
       " 'also': 1,\n",
       " 'gripping': 1,\n",
       " 'labels': 1,\n",
       " 'big': 1,\n",
       " 'set': 2,\n",
       " 'pizzas': 2,\n",
       " \"'d\": 3,\n",
       " 'like': 8,\n",
       " 'whether': 4,\n",
       " 'yes': 2,\n",
       " 'algorithm': 1,\n",
       " 'learn': 3,\n",
       " 'list': 1,\n",
       " 'ingredients': 1,\n",
       " 'It': 1,\n",
       " 'would': 2,\n",
       " 'pizza': 1,\n",
       " 'note': 1,\n",
       " 'might': 7,\n",
       " 'predicting': 2,\n",
       " 'continuous': 1,\n",
       " 'variable': 1,\n",
       " 'great': 2,\n",
       " 'sales': 1,\n",
       " 'forecasting': 1,\n",
       " 'houses': 1,\n",
       " 'encapsulate': 1,\n",
       " 'key': 3,\n",
       " 'visa': 2,\n",
       " 'clustering': 2,\n",
       " 'group': 2,\n",
       " 'people': 1,\n",
       " 'together': 3,\n",
       " 'wanted': 1,\n",
       " 'high': 2,\n",
       " 'performing': 5,\n",
       " 'low': 2,\n",
       " 'media': 1,\n",
       " 'employee': 1,\n",
       " 'value': 3,\n",
       " 'medium': 1,\n",
       " 'customers': 1,\n",
       " 'grouping': 1,\n",
       " 'dimensionality': 3,\n",
       " 'reduction': 3,\n",
       " 'chain': 1,\n",
       " 'dancing': 1,\n",
       " 'features': 1,\n",
       " \"'ve\": 9,\n",
       " 'got': 6,\n",
       " 'model': 7,\n",
       " 'lot': 3,\n",
       " 'start': 1,\n",
       " 'huge': 1,\n",
       " 'column': 1,\n",
       " 'sure': 3,\n",
       " 'columns': 3,\n",
       " 'important': 4,\n",
       " 'helps': 1,\n",
       " 'reduce': 1,\n",
       " 'number': 4,\n",
       " 'focus': 1,\n",
       " 'order': 3,\n",
       " 'suggest': 1,\n",
       " 'initial': 1,\n",
       " \"n't\": 2,\n",
       " 'Christopher': 1,\n",
       " 'robin': 1,\n",
       " 'courted': 1,\n",
       " 'takes': 2,\n",
       " 'care': 2,\n",
       " 'board': 1,\n",
       " 'reinforcement': 4,\n",
       " 'comes': 1,\n",
       " 'four': 1,\n",
       " 'agent': 2,\n",
       " 'action': 1,\n",
       " 'environment': 5,\n",
       " 'reward': 3,\n",
       " 'choose': 1,\n",
       " 'condition': 1,\n",
       " 'dog': 2,\n",
       " 'something': 1,\n",
       " 'piece': 1,\n",
       " 'food': 1,\n",
       " 'train': 2,\n",
       " 'models': 3,\n",
       " 'act': 1,\n",
       " 'correct': 1,\n",
       " 'given': 3,\n",
       " 'appropriate': 1,\n",
       " 'actions': 2,\n",
       " 'best': 3,\n",
       " 'techniques': 1,\n",
       " 'area': 1,\n",
       " 'fifty': 1,\n",
       " 'okay': 1,\n",
       " 'tell': 1,\n",
       " 'deeper': 1,\n",
       " 'deep': 7,\n",
       " 'plan': 1,\n",
       " '%': 1,\n",
       " 'HESITATION': 1,\n",
       " 'subset': 1,\n",
       " 'using': 2,\n",
       " 'neural': 3,\n",
       " 'networks': 3,\n",
       " 'multiple': 3,\n",
       " 'hidden': 2,\n",
       " 'late': 1,\n",
       " 'ever': 1,\n",
       " 'seen': 1,\n",
       " 'diagram': 1,\n",
       " 'looks': 1,\n",
       " 'sort': 1,\n",
       " 'representation': 1,\n",
       " 'network': 2,\n",
       " 'specifically': 1,\n",
       " 'case': 1,\n",
       " 'layers': 1,\n",
       " 'onion': 1,\n",
       " 'Shrek': 1,\n",
       " 'covers': 1,\n",
       " 'phone': 1,\n",
       " 'decide': 1,\n",
       " 'practise': 1,\n",
       " 'sit': 1,\n",
       " 'India': 1,\n",
       " 'basically': 2,\n",
       " 'art': 1,\n",
       " 'extracting': 1,\n",
       " 'knowledge': 1,\n",
       " 'insight': 1,\n",
       " 'meaning': 1,\n",
       " 'components': 1,\n",
       " 'science': 2,\n",
       " 'cristiana': 1,\n",
       " 'framework': 4,\n",
       " 'Crispian': 1,\n",
       " 'stands': 1,\n",
       " 'cross': 1,\n",
       " 'industry': 1,\n",
       " 'standard': 1,\n",
       " 'process': 2,\n",
       " 'mining': 1,\n",
       " 'along': 1,\n",
       " 'producing': 1,\n",
       " 'good': 1,\n",
       " 'project': 1,\n",
       " 'sixty': 1,\n",
       " 'steps': 2,\n",
       " 'date': 2,\n",
       " 'business': 3,\n",
       " 'understanding': 6,\n",
       " 'working': 1,\n",
       " 'operate': 1,\n",
       " 'missing': 2,\n",
       " 'values': 2,\n",
       " 'visualising': 1,\n",
       " 'taking': 1,\n",
       " 'summary': 1,\n",
       " 'statistics': 1,\n",
       " 'preparation': 4,\n",
       " 'getting': 1,\n",
       " 'ready': 1,\n",
       " 'modelling': 3,\n",
       " 'step': 5,\n",
       " 'feature': 1,\n",
       " 'engineering': 1,\n",
       " 'increasing': 1,\n",
       " 'feel': 1,\n",
       " 'splitting': 1,\n",
       " 'training': 2,\n",
       " 'testing': 1,\n",
       " 'favourite': 1,\n",
       " 'algorithms': 2,\n",
       " 'trained': 2,\n",
       " 'evaluation': 4,\n",
       " 'want': 1,\n",
       " 'make': 1,\n",
       " 'work': 2,\n",
       " 'deployed': 2,\n",
       " 'real': 1,\n",
       " 'world': 1,\n",
       " 'try': 1,\n",
       " 'check': 1,\n",
       " 'likely': 2,\n",
       " 'metrics': 1,\n",
       " 'gone': 1,\n",
       " 'last': 1,\n",
       " 'go': 2,\n",
       " 'deploy': 1,\n",
       " 'release': 1,\n",
       " 'rest': 1,\n",
       " 'API': 1,\n",
       " 'containerized': 1,\n",
       " 'save': 1,\n",
       " 'wondering': 1,\n",
       " 'use': 2,\n",
       " 'elsewhere': 1,\n",
       " 'Christie': 1,\n",
       " 'rumour': 1,\n",
       " 'Barry': 1,\n",
       " 'drove': 1,\n",
       " 'directly': 1,\n",
       " 'medical': 1,\n",
       " 'emergency': 1,\n",
       " 'department': 1,\n",
       " 'deployment': 1,\n",
       " 'talked': 1,\n",
       " 'period': 1,\n",
       " 'pipe': 1,\n",
       " 'packages': 2,\n",
       " 'used': 1,\n",
       " 'sites': 1,\n",
       " 'part': 1,\n",
       " 'painted': 1,\n",
       " 'matte': 1,\n",
       " 'properly': 1,\n",
       " 'Probably': 1,\n",
       " 'floating': 1,\n",
       " 'around': 2,\n",
       " 'panders': 1,\n",
       " 'traverse': 1,\n",
       " 'manipulation': 1,\n",
       " 'maps': 1,\n",
       " 'leave': 1,\n",
       " 'seaborne': 1,\n",
       " 'visualise': 1,\n",
       " 'even': 1,\n",
       " 'psychic': 1,\n",
       " 'learnt': 1,\n",
       " 'quite': 1,\n",
       " 'gives': 1,\n",
       " 'powerful': 1,\n",
       " 'utilities': 1,\n",
       " 'declining': 1,\n",
       " 'becoming': 1,\n",
       " 'increasingly': 1,\n",
       " 'popular': 1,\n",
       " 'large': 1,\n",
       " 'libraries': 1,\n",
       " 'notable': 1,\n",
       " 'attempts': 1,\n",
       " 'load': 1,\n",
       " 'carriers': 1,\n",
       " 'pi': 1,\n",
       " 'torch': 1,\n",
       " 'piano': 1,\n",
       " 'name': 1,\n",
       " 'wraps': 1,\n",
       " 'old': 1,\n",
       " 'dear': 1,\n",
       " 'thanks': 1,\n",
       " 'much': 1,\n",
       " 'choosing': 1,\n",
       " 'guys': 1,\n",
       " 'hopefully': 1,\n",
       " 'found': 1,\n",
       " 'video': 1,\n",
       " 'useful': 1,\n",
       " 'give': 1,\n",
       " 'thumbs': 1,\n",
       " 'hit': 1,\n",
       " 'strive': 1,\n",
       " 'T': 1}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum_frequency = max(word_frequencies.values())\n",
    "\n",
    "for word in word_frequencies.keys():\n",
    "    word_frequencies[word] = (word_frequencies[word]/maximum_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maximum_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ever': 0.02857142857142857,\n",
       " 'wondered': 0.02857142857142857,\n",
       " 'differences': 0.02857142857142857,\n",
       " '.': 0.2,\n",
       " 'M.': 0.02857142857142857,\n",
       " 'L.': 0.05714285714285714,\n",
       " 'deal': 0.11428571428571428,\n",
       " 'DS': 0.05714285714285714,\n",
       " 'well': 0.2571428571428571,\n",
       " \"'re\": 0.08571428571428572,\n",
       " 'explore': 0.08571428571428572,\n",
       " 'today': 0.02857142857142857,\n",
       " 'stated': 0.02857142857142857,\n",
       " 'let': 0.05714285714285714,\n",
       " \"'s\": 0.4,\n",
       " 'dive': 0.02857142857142857,\n",
       " 'right': 0.08571428571428572,\n",
       " 'AI': 0.11428571428571428,\n",
       " 'versus': 0.11428571428571428,\n",
       " 'ML': 0.05714285714285714,\n",
       " 'whole': 0.17142857142857143,\n",
       " 'bunch': 0.14285714285714285,\n",
       " 'judging': 0.02857142857142857,\n",
       " 'within': 0.05714285714285714,\n",
       " 'clarify': 0.02857142857142857,\n",
       " 'took': 0.02857142857142857,\n",
       " 'things': 0.17142857142857143,\n",
       " 'often': 0.05714285714285714,\n",
       " 'take': 0.11428571428571428,\n",
       " 'look': 0.14285714285714285,\n",
       " 'A.': 0.17142857142857143,\n",
       " 'R': 0.02857142857142857,\n",
       " '..': 0.05714285714285714,\n",
       " 'So': 0.02857142857142857,\n",
       " 'I.': 0.08571428571428572,\n",
       " 'really': 0.37142857142857144,\n",
       " 'ability': 0.2857142857142857,\n",
       " 'computers': 0.05714285714285714,\n",
       " 'machines': 0.02857142857142857,\n",
       " 'perform': 0.14285714285714285,\n",
       " 'tasks': 0.08571428571428572,\n",
       " 'without': 0.02857142857142857,\n",
       " 'explicitly': 0.02857142857142857,\n",
       " 'programming': 0.05714285714285714,\n",
       " 'otherwise': 0.02857142857142857,\n",
       " 'known': 0.02857142857142857,\n",
       " 'machine': 0.5714285714285714,\n",
       " 'think': 0.11428571428571428,\n",
       " 'typically': 0.14285714285714285,\n",
       " 'break': 0.05714285714285714,\n",
       " 'two': 0.11428571428571428,\n",
       " 'categories': 0.14285714285714285,\n",
       " 'generally': 0.02857142857142857,\n",
       " 'I': 0.2571428571428571,\n",
       " 'know': 0.05714285714285714,\n",
       " 'Generally': 0.02857142857142857,\n",
       " 'refers': 0.02857142857142857,\n",
       " 'computer': 0.05714285714285714,\n",
       " 'able': 0.08571428571428572,\n",
       " 'handle': 0.05714285714285714,\n",
       " 'wide': 0.02857142857142857,\n",
       " 'variety': 0.02857142857142857,\n",
       " 'type': 0.11428571428571428,\n",
       " 'humans': 0.02857142857142857,\n",
       " 'heap': 0.02857142857142857,\n",
       " 'stuff': 0.02857142857142857,\n",
       " 'see': 0.08571428571428572,\n",
       " 'speak': 0.02857142857142857,\n",
       " 'read': 0.02857142857142857,\n",
       " 'drive': 0.02857142857142857,\n",
       " 'range': 0.08571428571428572,\n",
       " 'broad': 0.02857142857142857,\n",
       " 'similar': 0.08571428571428572,\n",
       " 'human': 0.02857142857142857,\n",
       " 'referred': 0.02857142857142857,\n",
       " 'general': 0.2,\n",
       " 'Now': 0.02857142857142857,\n",
       " 'still': 0.02857142857142857,\n",
       " 'little': 0.08571428571428572,\n",
       " 'bit': 0.11428571428571428,\n",
       " 'away': 0.02857142857142857,\n",
       " 'true': 0.02857142857142857,\n",
       " 'either': 0.08571428571428572,\n",
       " 'say': 0.02857142857142857,\n",
       " 'come': 0.02857142857142857,\n",
       " 'narrow': 0.2,\n",
       " 'hand': 0.14285714285714285,\n",
       " 'simple': 0.02857142857142857,\n",
       " 'time': 0.14285714285714285,\n",
       " 'could': 0.11428571428571428,\n",
       " 'possibly': 0.02857142857142857,\n",
       " 'translate': 0.02857142857142857,\n",
       " 'speech': 0.02857142857142857,\n",
       " 'text': 0.02857142857142857,\n",
       " 'classify': 0.02857142857142857,\n",
       " 'images': 0.02857142857142857,\n",
       " 'different': 0.11428571428571428,\n",
       " 'predict': 0.05714285714285714,\n",
       " 'prices': 0.05714285714285714,\n",
       " 'example': 0.05714285714285714,\n",
       " 'examples': 0.05714285714285714,\n",
       " \"'m\": 0.05714285714285714,\n",
       " 'going': 0.08571428571428572,\n",
       " 'painting': 0.02857142857142857,\n",
       " 'visual': 0.02857142857142857,\n",
       " 'imagery': 0.02857142857142857,\n",
       " 'help': 0.2,\n",
       " 'remember': 0.37142857142857144,\n",
       " 'topics': 0.02857142857142857,\n",
       " 'first': 0.05714285714285714,\n",
       " 'one': 0.08571428571428572,\n",
       " 'terms': 0.11428571428571428,\n",
       " 'breaking': 0.02857142857142857,\n",
       " 'hour': 0.02857142857142857,\n",
       " 'picture': 0.02857142857142857,\n",
       " 'skinny': 0.02857142857142857,\n",
       " 'mind': 0.02857142857142857,\n",
       " 'way': 0.3142857142857143,\n",
       " 'types': 0.11428571428571428,\n",
       " 'R.': 0.02857142857142857,\n",
       " 'America': 0.02857142857142857,\n",
       " 'onto': 0.02857142857142857,\n",
       " 'next': 0.08571428571428572,\n",
       " 'learning': 1.0,\n",
       " 'broken': 0.05714285714285714,\n",
       " 'fit': 0.05714285714285714,\n",
       " 'application': 0.02857142857142857,\n",
       " 'item': 0.02857142857142857,\n",
       " 'specific': 0.11428571428571428,\n",
       " 'talk': 0.02857142857142857,\n",
       " 'compared': 0.02857142857142857,\n",
       " 'traditional': 0.05714285714285714,\n",
       " 'programme': 0.02857142857142857,\n",
       " 'applied': 0.02857142857142857,\n",
       " 'data': 0.7142857142857143,\n",
       " 'plus': 0.05714285714285714,\n",
       " 'rules': 0.05714285714285714,\n",
       " 'conditional': 0.02857142857142857,\n",
       " 'logic': 0.02857142857142857,\n",
       " 'get': 0.14285714285714285,\n",
       " 'answers': 0.08571428571428572,\n",
       " 'provide': 0.02857142857142857,\n",
       " 'historical': 0.02857142857142857,\n",
       " 'pass': 0.08571428571428572,\n",
       " 'new': 0.08571428571428572,\n",
       " 'change': 0.02857142857142857,\n",
       " 'paradigm': 0.02857142857142857,\n",
       " 'scientists': 0.02857142857142857,\n",
       " 'engineers': 0.02857142857142857,\n",
       " 'building': 0.02857142857142857,\n",
       " 'programmes': 0.02857142857142857,\n",
       " 'days': 0.02857142857142857,\n",
       " 'typical': 0.02857142857142857,\n",
       " 'probably': 0.05714285714285714,\n",
       " 'three': 0.02857142857142857,\n",
       " 'supervised': 0.2,\n",
       " 'unsupervised': 0.14285714285714285,\n",
       " 'semi': 0.05714285714285714,\n",
       " 'supervisor': 0.02857142857142857,\n",
       " 'broadly': 0.02857142857142857,\n",
       " 'classification': 0.11428571428571428,\n",
       " 'regression': 0.11428571428571428,\n",
       " 'also': 0.02857142857142857,\n",
       " 'gripping': 0.02857142857142857,\n",
       " 'labels': 0.02857142857142857,\n",
       " 'big': 0.02857142857142857,\n",
       " 'set': 0.05714285714285714,\n",
       " 'pizzas': 0.05714285714285714,\n",
       " \"'d\": 0.08571428571428572,\n",
       " 'like': 0.22857142857142856,\n",
       " 'whether': 0.11428571428571428,\n",
       " 'yes': 0.05714285714285714,\n",
       " 'algorithm': 0.02857142857142857,\n",
       " 'learn': 0.08571428571428572,\n",
       " 'list': 0.02857142857142857,\n",
       " 'ingredients': 0.02857142857142857,\n",
       " 'It': 0.02857142857142857,\n",
       " 'would': 0.05714285714285714,\n",
       " 'pizza': 0.02857142857142857,\n",
       " 'note': 0.02857142857142857,\n",
       " 'might': 0.2,\n",
       " 'predicting': 0.05714285714285714,\n",
       " 'continuous': 0.02857142857142857,\n",
       " 'variable': 0.02857142857142857,\n",
       " 'great': 0.05714285714285714,\n",
       " 'sales': 0.02857142857142857,\n",
       " 'forecasting': 0.02857142857142857,\n",
       " 'houses': 0.02857142857142857,\n",
       " 'encapsulate': 0.02857142857142857,\n",
       " 'key': 0.08571428571428572,\n",
       " 'visa': 0.05714285714285714,\n",
       " 'clustering': 0.05714285714285714,\n",
       " 'group': 0.05714285714285714,\n",
       " 'people': 0.02857142857142857,\n",
       " 'together': 0.08571428571428572,\n",
       " 'wanted': 0.02857142857142857,\n",
       " 'high': 0.05714285714285714,\n",
       " 'performing': 0.14285714285714285,\n",
       " 'low': 0.05714285714285714,\n",
       " 'media': 0.02857142857142857,\n",
       " 'employee': 0.02857142857142857,\n",
       " 'value': 0.08571428571428572,\n",
       " 'medium': 0.02857142857142857,\n",
       " 'customers': 0.02857142857142857,\n",
       " 'grouping': 0.02857142857142857,\n",
       " 'dimensionality': 0.08571428571428572,\n",
       " 'reduction': 0.08571428571428572,\n",
       " 'chain': 0.02857142857142857,\n",
       " 'dancing': 0.02857142857142857,\n",
       " 'features': 0.02857142857142857,\n",
       " \"'ve\": 0.2571428571428571,\n",
       " 'got': 0.17142857142857143,\n",
       " 'model': 0.2,\n",
       " 'lot': 0.08571428571428572,\n",
       " 'start': 0.02857142857142857,\n",
       " 'huge': 0.02857142857142857,\n",
       " 'column': 0.02857142857142857,\n",
       " 'sure': 0.08571428571428572,\n",
       " 'columns': 0.08571428571428572,\n",
       " 'important': 0.11428571428571428,\n",
       " 'helps': 0.02857142857142857,\n",
       " 'reduce': 0.02857142857142857,\n",
       " 'number': 0.11428571428571428,\n",
       " 'focus': 0.02857142857142857,\n",
       " 'order': 0.08571428571428572,\n",
       " 'suggest': 0.02857142857142857,\n",
       " 'initial': 0.02857142857142857,\n",
       " \"n't\": 0.05714285714285714,\n",
       " 'Christopher': 0.02857142857142857,\n",
       " 'robin': 0.02857142857142857,\n",
       " 'courted': 0.02857142857142857,\n",
       " 'takes': 0.05714285714285714,\n",
       " 'care': 0.05714285714285714,\n",
       " 'board': 0.02857142857142857,\n",
       " 'reinforcement': 0.11428571428571428,\n",
       " 'comes': 0.02857142857142857,\n",
       " 'four': 0.02857142857142857,\n",
       " 'agent': 0.05714285714285714,\n",
       " 'action': 0.02857142857142857,\n",
       " 'environment': 0.14285714285714285,\n",
       " 'reward': 0.08571428571428572,\n",
       " 'choose': 0.02857142857142857,\n",
       " 'condition': 0.02857142857142857,\n",
       " 'dog': 0.05714285714285714,\n",
       " 'something': 0.02857142857142857,\n",
       " 'piece': 0.02857142857142857,\n",
       " 'food': 0.02857142857142857,\n",
       " 'train': 0.05714285714285714,\n",
       " 'models': 0.08571428571428572,\n",
       " 'act': 0.02857142857142857,\n",
       " 'correct': 0.02857142857142857,\n",
       " 'given': 0.08571428571428572,\n",
       " 'appropriate': 0.02857142857142857,\n",
       " 'actions': 0.05714285714285714,\n",
       " 'best': 0.08571428571428572,\n",
       " 'techniques': 0.02857142857142857,\n",
       " 'area': 0.02857142857142857,\n",
       " 'fifty': 0.02857142857142857,\n",
       " 'okay': 0.02857142857142857,\n",
       " 'tell': 0.02857142857142857,\n",
       " 'deeper': 0.02857142857142857,\n",
       " 'deep': 0.2,\n",
       " 'plan': 0.02857142857142857,\n",
       " '%': 0.02857142857142857,\n",
       " 'HESITATION': 0.02857142857142857,\n",
       " 'subset': 0.02857142857142857,\n",
       " 'using': 0.05714285714285714,\n",
       " 'neural': 0.08571428571428572,\n",
       " 'networks': 0.08571428571428572,\n",
       " 'multiple': 0.08571428571428572,\n",
       " 'hidden': 0.05714285714285714,\n",
       " 'late': 0.02857142857142857,\n",
       " 'ever': 0.02857142857142857,\n",
       " 'seen': 0.02857142857142857,\n",
       " 'diagram': 0.02857142857142857,\n",
       " 'looks': 0.02857142857142857,\n",
       " 'sort': 0.02857142857142857,\n",
       " 'representation': 0.02857142857142857,\n",
       " 'network': 0.05714285714285714,\n",
       " 'specifically': 0.02857142857142857,\n",
       " 'case': 0.02857142857142857,\n",
       " 'layers': 0.02857142857142857,\n",
       " 'onion': 0.02857142857142857,\n",
       " 'Shrek': 0.02857142857142857,\n",
       " 'covers': 0.02857142857142857,\n",
       " 'phone': 0.02857142857142857,\n",
       " 'decide': 0.02857142857142857,\n",
       " 'practise': 0.02857142857142857,\n",
       " 'sit': 0.02857142857142857,\n",
       " 'India': 0.02857142857142857,\n",
       " 'basically': 0.05714285714285714,\n",
       " 'art': 0.02857142857142857,\n",
       " 'extracting': 0.02857142857142857,\n",
       " 'knowledge': 0.02857142857142857,\n",
       " 'insight': 0.02857142857142857,\n",
       " 'meaning': 0.02857142857142857,\n",
       " 'components': 0.02857142857142857,\n",
       " 'science': 0.05714285714285714,\n",
       " 'cristiana': 0.02857142857142857,\n",
       " 'framework': 0.11428571428571428,\n",
       " 'Crispian': 0.02857142857142857,\n",
       " 'stands': 0.02857142857142857,\n",
       " 'cross': 0.02857142857142857,\n",
       " 'industry': 0.02857142857142857,\n",
       " 'standard': 0.02857142857142857,\n",
       " 'process': 0.05714285714285714,\n",
       " 'mining': 0.02857142857142857,\n",
       " 'along': 0.02857142857142857,\n",
       " 'producing': 0.02857142857142857,\n",
       " 'good': 0.02857142857142857,\n",
       " 'project': 0.02857142857142857,\n",
       " 'sixty': 0.02857142857142857,\n",
       " 'steps': 0.05714285714285714,\n",
       " 'date': 0.05714285714285714,\n",
       " 'business': 0.08571428571428572,\n",
       " 'understanding': 0.17142857142857143,\n",
       " 'working': 0.02857142857142857,\n",
       " 'operate': 0.02857142857142857,\n",
       " 'missing': 0.05714285714285714,\n",
       " 'values': 0.05714285714285714,\n",
       " 'visualising': 0.02857142857142857,\n",
       " 'taking': 0.02857142857142857,\n",
       " 'summary': 0.02857142857142857,\n",
       " 'statistics': 0.02857142857142857,\n",
       " 'preparation': 0.11428571428571428,\n",
       " 'getting': 0.02857142857142857,\n",
       " 'ready': 0.02857142857142857,\n",
       " 'modelling': 0.08571428571428572,\n",
       " 'step': 0.14285714285714285,\n",
       " 'feature': 0.02857142857142857,\n",
       " 'engineering': 0.02857142857142857,\n",
       " 'increasing': 0.02857142857142857,\n",
       " 'feel': 0.02857142857142857,\n",
       " 'splitting': 0.02857142857142857,\n",
       " 'training': 0.05714285714285714,\n",
       " 'testing': 0.02857142857142857,\n",
       " 'favourite': 0.02857142857142857,\n",
       " 'algorithms': 0.05714285714285714,\n",
       " 'trained': 0.05714285714285714,\n",
       " 'evaluation': 0.11428571428571428,\n",
       " 'want': 0.02857142857142857,\n",
       " 'make': 0.02857142857142857,\n",
       " 'work': 0.05714285714285714,\n",
       " 'deployed': 0.05714285714285714,\n",
       " 'real': 0.02857142857142857,\n",
       " 'world': 0.02857142857142857,\n",
       " 'try': 0.02857142857142857,\n",
       " 'check': 0.02857142857142857,\n",
       " 'likely': 0.05714285714285714,\n",
       " 'metrics': 0.02857142857142857,\n",
       " 'gone': 0.02857142857142857,\n",
       " 'last': 0.02857142857142857,\n",
       " 'go': 0.05714285714285714,\n",
       " 'deploy': 0.02857142857142857,\n",
       " 'release': 0.02857142857142857,\n",
       " 'rest': 0.02857142857142857,\n",
       " 'API': 0.02857142857142857,\n",
       " 'containerized': 0.02857142857142857,\n",
       " 'save': 0.02857142857142857,\n",
       " 'wondering': 0.02857142857142857,\n",
       " 'use': 0.05714285714285714,\n",
       " 'elsewhere': 0.02857142857142857,\n",
       " 'Christie': 0.02857142857142857,\n",
       " 'rumour': 0.02857142857142857,\n",
       " 'Barry': 0.02857142857142857,\n",
       " 'drove': 0.02857142857142857,\n",
       " 'directly': 0.02857142857142857,\n",
       " 'medical': 0.02857142857142857,\n",
       " 'emergency': 0.02857142857142857,\n",
       " 'department': 0.02857142857142857,\n",
       " 'deployment': 0.02857142857142857,\n",
       " 'talked': 0.02857142857142857,\n",
       " 'period': 0.02857142857142857,\n",
       " 'pipe': 0.02857142857142857,\n",
       " 'packages': 0.05714285714285714,\n",
       " 'used': 0.02857142857142857,\n",
       " 'sites': 0.02857142857142857,\n",
       " 'part': 0.02857142857142857,\n",
       " 'painted': 0.02857142857142857,\n",
       " 'matte': 0.02857142857142857,\n",
       " 'properly': 0.02857142857142857,\n",
       " 'Probably': 0.02857142857142857,\n",
       " 'floating': 0.02857142857142857,\n",
       " 'around': 0.05714285714285714,\n",
       " 'panders': 0.02857142857142857,\n",
       " 'traverse': 0.02857142857142857,\n",
       " 'manipulation': 0.02857142857142857,\n",
       " 'maps': 0.02857142857142857,\n",
       " 'leave': 0.02857142857142857,\n",
       " 'seaborne': 0.02857142857142857,\n",
       " 'visualise': 0.02857142857142857,\n",
       " 'even': 0.02857142857142857,\n",
       " 'psychic': 0.02857142857142857,\n",
       " 'learnt': 0.02857142857142857,\n",
       " 'quite': 0.02857142857142857,\n",
       " 'gives': 0.02857142857142857,\n",
       " 'powerful': 0.02857142857142857,\n",
       " 'utilities': 0.02857142857142857,\n",
       " 'declining': 0.02857142857142857,\n",
       " 'becoming': 0.02857142857142857,\n",
       " 'increasingly': 0.02857142857142857,\n",
       " 'popular': 0.02857142857142857,\n",
       " 'large': 0.02857142857142857,\n",
       " 'libraries': 0.02857142857142857,\n",
       " 'notable': 0.02857142857142857,\n",
       " 'attempts': 0.02857142857142857,\n",
       " 'load': 0.02857142857142857,\n",
       " 'carriers': 0.02857142857142857,\n",
       " 'pi': 0.02857142857142857,\n",
       " 'torch': 0.02857142857142857,\n",
       " 'piano': 0.02857142857142857,\n",
       " 'name': 0.02857142857142857,\n",
       " 'wraps': 0.02857142857142857,\n",
       " 'old': 0.02857142857142857,\n",
       " 'dear': 0.02857142857142857,\n",
       " 'thanks': 0.02857142857142857,\n",
       " 'much': 0.02857142857142857,\n",
       " 'choosing': 0.02857142857142857,\n",
       " 'guys': 0.02857142857142857,\n",
       " 'hopefully': 0.02857142857142857,\n",
       " 'found': 0.02857142857142857,\n",
       " 'video': 0.02857142857142857,\n",
       " 'useful': 0.02857142857142857,\n",
       " 'give': 0.02857142857142857,\n",
       " 'thumbs': 0.02857142857142857,\n",
       " 'hit': 0.02857142857142857,\n",
       " 'strive': 0.02857142857142857,\n",
       " 'T': 0.02857142857142857}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_scores = {}\n",
    "for sent in text:\n",
    "    for word in nltk.word_tokenize(sent.lower()):\n",
    "        if word in word_frequencies.keys():\n",
    "            if len(sent.split(' ')) < 100:\n",
    "                if sent not in sentence_scores.keys():\n",
    "                    sentence_scores[sent] = word_frequencies[word]\n",
    "                else:\n",
    "                    sentence_scores[sent] += word_frequencies[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ever wondered about the differences between.\\n': 0.2857142857142857,\n",
       " \"M. L. deal and DS well we're about to explore all of those today stated so let's dive right into it so AI versus ML this is deal with the DS a whole bunch of judging but within a clarify all of that right up so it took things often take a look at A. R..\\n\": 2.485714285714285,\n",
       " 'So A. I. is really to do with the ability of computers and machines to perform tasks without explicitly programming them otherwise known as the ability for computers and machine to think by themselves so we typically break out into two categories these are generally I know a.\\n': 2.9142857142857137,\n",
       " 'Generally I typically refers to the ability for a computer a machine to be able to handle a wide variety of type I think humans have the ability to do a whole heap of stuff we can see we can speak we can here we can read we can drive we can do a whole range of things the ability for AI and machine to be able to do a broad range of tasks similar to human is what we typically referred to as general.\\n': 4.514285714285714}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generally I typically refers to the ability for a computer a machine to be able to handle a wide variety of type I think humans have the ability to do a whole heap of stuff we can see we can speak we can here we can read we can drive we can do a whole range of things the ability for AI and machine to be able to do a broad range of tasks similar to human is what we typically referred to as general.\n",
      " So A. I. is really to do with the ability of computers and machines to perform tasks without explicitly programming them otherwise known as the ability for computers and machine to think by themselves so we typically break out into two categories these are generally I know a.\n",
      " M. L. deal and DS well we're about to explore all of those today stated so let's dive right into it so AI versus ML this is deal with the DS a whole bunch of judging but within a clarify all of that right up so it took things often take a look at A. R..\n",
      " Ever wondered about the differences between.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "summary_sentences = heapq.nlargest(10, sentence_scores, key = sentence_scores.get)\n",
    "\n",
    "summary = ' '.join(summary_sentences)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('summarised_text.txt','w') as out:\n",
    "    out.writelines(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
